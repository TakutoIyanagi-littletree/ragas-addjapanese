{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be79b52",
   "metadata": {},
   "source": [
    "### Generate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8f702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ragas/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from llama_index import download_loader\n",
    "from ragas.testset import TestsetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b4cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SemanticScholarReader = download_loader(\"SemanticScholarReader\")\n",
    "loader = SemanticScholarReader()\n",
    "# narrow down the search space\n",
    "query_space = \"large language models\"\n",
    "# increase limit to get more documents\n",
    "documents = loader.load_data(query=query_space, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04cc99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:53,  3.55s/it]                                                                 \n"
     ]
    }
   ],
   "source": [
    "testsetgenerator = TestsetGenerator.from_default()\n",
    "test_size = 5  # Number of samples to generate\n",
    "testset = testsetgenerator.generate(documents, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe804d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e58bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the proposed method for reducing the n...</td>\n",
       "      <td>- We propose Low-Rank Adaptation, or LoRA, whi...</td>\n",
       "      <td>The proposed method for reducing the number of...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the \"Let's think step b...</td>\n",
       "      <td>- Providing these steps for prompting demonstr...</td>\n",
       "      <td>The purpose of the \"Let's think step by step\" ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What technique improves the performance of lar...</td>\n",
       "      <td>- \"We explore how generating a chain of though...</td>\n",
       "      <td>The technique that improves the performance of...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Codex's success rate in problem-solvin...</td>\n",
       "      <td>- On HumanEval, a new evaluation set we releas...</td>\n",
       "      <td>Codex's success rate in problem-solving accord...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are emergent abilities of large language ...</td>\n",
       "      <td>- Large Language Models are Zero-Shot Reasoner...</td>\n",
       "      <td>The emergent abilities of large language model...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the proposed method for reducing the n...   \n",
       "1  What is the purpose of the \"Let's think step b...   \n",
       "2  What technique improves the performance of lar...   \n",
       "3  What is Codex's success rate in problem-solvin...   \n",
       "4  What are emergent abilities of large language ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  - We propose Low-Rank Adaptation, or LoRA, whi...   \n",
       "1  - Providing these steps for prompting demonstr...   \n",
       "2  - \"We explore how generating a chain of though...   \n",
       "3  - On HumanEval, a new evaluation set we releas...   \n",
       "4  - Large Language Models are Zero-Shot Reasoner...   \n",
       "\n",
       "                                              answer question_type  \\\n",
       "0  The proposed method for reducing the number of...        simple   \n",
       "1  The purpose of the \"Let's think step by step\" ...        simple   \n",
       "2  The technique that improves the performance of...        simple   \n",
       "3  Codex's success rate in problem-solving accord...     reasoning   \n",
       "4  The emergent abilities of large language model...        simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b03469",
   "metadata": {},
   "source": [
    "## Build your RAG & collect questions, retrieved context and generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc576c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a2f6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext,OpenAIEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5a05cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = OpenAIEmbedding()\n",
    "\n",
    "flag_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "583dbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_query_engine(embed_model):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=ServiceContext.from_defaults(chunk_size=512),\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "\n",
    "    query_engine = vector_index.as_query_engine()\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4584eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = test_df['question'].values.tolist()\n",
    "test_answers = [[item] for item in test_df['answer'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee3849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e1da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1/1 [00:15<00:00, 15.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.llama_index import evaluate\n",
    "query_engine1 = build_query_engine(openai_model)\n",
    "result = evaluate(query_engine1, metrics, test_questions, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "411624b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ragas_score': 0.3950, 'context_precision': 0.2622, 'context_recall': 0.8000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a15bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the proposed method for reducing the n...</td>\n",
       "      <td>[Training Compute-Optimal Large Language Model...</td>\n",
       "      <td>The proposed method for reducing the number of...</td>\n",
       "      <td>[The proposed method for reducing the number o...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the \"Let's think step b...</td>\n",
       "      <td>[Chain of Thought Prompting Elicits Reasoning ...</td>\n",
       "      <td>The purpose of the \"Let's think step by step\" ...</td>\n",
       "      <td>[The purpose of the \"Let's think step by step\"...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What technique improves the performance of lar...</td>\n",
       "      <td>[Large Language Models are Zero-Shot Reasoners...</td>\n",
       "      <td>Adding the prompt \"Let's think step by step\" b...</td>\n",
       "      <td>[The technique that improves the performance o...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Codex's success rate in problem-solvin...</td>\n",
       "      <td>[A distinct production version of Codex powers...</td>\n",
       "      <td>Codex's success rate in problem-solving accord...</td>\n",
       "      <td>[Codex's success rate in problem-solving accor...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are emergent abilities of large language ...</td>\n",
       "      <td>[Emergent Abilities of Large Language Models S...</td>\n",
       "      <td>Emergent abilities of large language models ar...</td>\n",
       "      <td>[The emergent abilities of large language mode...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the proposed method for reducing the n...   \n",
       "1  What is the purpose of the \"Let's think step b...   \n",
       "2  What technique improves the performance of lar...   \n",
       "3  What is Codex's success rate in problem-solvin...   \n",
       "4  What are emergent abilities of large language ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Training Compute-Optimal Large Language Model...   \n",
       "1  [Chain of Thought Prompting Elicits Reasoning ...   \n",
       "2  [Large Language Models are Zero-Shot Reasoners...   \n",
       "3  [A distinct production version of Codex powers...   \n",
       "4  [Emergent Abilities of Large Language Models S...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The proposed method for reducing the number of...   \n",
       "1  The purpose of the \"Let's think step by step\" ...   \n",
       "2  Adding the prompt \"Let's think step by step\" b...   \n",
       "3  Codex's success rate in problem-solving accord...   \n",
       "4  Emergent abilities of large language models ar...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [The proposed method for reducing the number o...           0.076923   \n",
       "1  [The purpose of the \"Let's think step by step\"...           0.055556   \n",
       "2  [The technique that improves the performance o...           0.500000   \n",
       "3  [Codex's success rate in problem-solving accor...           0.250000   \n",
       "4  [The emergent abilities of large language mode...           0.428571   \n",
       "\n",
       "   context_recall  \n",
       "0             0.0  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52e45ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.15s/it]\n"
     ]
    }
   ],
   "source": [
    "query_engine2 = build_query_engine(flag_model)\n",
    "result = evaluate(query_engine2, metrics, test_questions, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab250ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ragas_score': 0.3950, 'context_precision': 0.2622, 'context_recall': 0.8000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfc73b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the proposed method for reducing the n...</td>\n",
       "      <td>[Training Compute-Optimal Large Language Model...</td>\n",
       "      <td>The proposed method for reducing the number of...</td>\n",
       "      <td>[The proposed method for reducing the number o...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the \"Let's think step b...</td>\n",
       "      <td>[Chain of Thought Prompting Elicits Reasoning ...</td>\n",
       "      <td>The purpose of the \"Let's think step by step\" ...</td>\n",
       "      <td>[The purpose of the \"Let's think step by step\"...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What technique improves the performance of lar...</td>\n",
       "      <td>[Large Language Models are Zero-Shot Reasoners...</td>\n",
       "      <td>Adding the prompt \"Let's think step by step\" b...</td>\n",
       "      <td>[The technique that improves the performance o...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Codex's success rate in problem-solvin...</td>\n",
       "      <td>[A distinct production version of Codex powers...</td>\n",
       "      <td>Codex's success rate in problem-solving accord...</td>\n",
       "      <td>[Codex's success rate in problem-solving accor...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are emergent abilities of large language ...</td>\n",
       "      <td>[Emergent Abilities of Large Language Models S...</td>\n",
       "      <td>Emergent abilities of large language models ar...</td>\n",
       "      <td>[The emergent abilities of large language mode...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the proposed method for reducing the n...   \n",
       "1  What is the purpose of the \"Let's think step b...   \n",
       "2  What technique improves the performance of lar...   \n",
       "3  What is Codex's success rate in problem-solvin...   \n",
       "4  What are emergent abilities of large language ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Training Compute-Optimal Large Language Model...   \n",
       "1  [Chain of Thought Prompting Elicits Reasoning ...   \n",
       "2  [Large Language Models are Zero-Shot Reasoners...   \n",
       "3  [A distinct production version of Codex powers...   \n",
       "4  [Emergent Abilities of Large Language Models S...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The proposed method for reducing the number of...   \n",
       "1  The purpose of the \"Let's think step by step\" ...   \n",
       "2  Adding the prompt \"Let's think step by step\" b...   \n",
       "3  Codex's success rate in problem-solving accord...   \n",
       "4  Emergent abilities of large language models ar...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [The proposed method for reducing the number o...           0.076923   \n",
       "1  [The purpose of the \"Let's think step by step\"...           0.055556   \n",
       "2  [The technique that improves the performance o...           0.500000   \n",
       "3  [Codex's success rate in problem-solving accor...           0.250000   \n",
       "4  [The emergent abilities of large language mode...           0.428571   \n",
       "\n",
       "   context_recall  \n",
       "0             0.0  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cf223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
