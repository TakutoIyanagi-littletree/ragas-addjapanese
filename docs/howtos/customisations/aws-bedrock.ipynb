{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c249b40",
   "metadata": {},
   "source": [
    "# Using Amazon Bedrock\n",
    "\n",
    "This tutorial will show you how to use Amazon Bedrock endpoints and LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/austinmw/ragas@bedrock\n",
    "#%pip install \"langchain>=0.0.336\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b5e01",
   "metadata": {},
   "source": [
    "### Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b658e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fiqa (/home/ec2-user/.cache/huggingface/datasets/explodinggradients___fiqa/ragas_eval/1.0.0/3dc7b639f5b4b16509a3299a2ceb78bf5fe98ee6b5fee25e7d5e4d290c88efb8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b3783b7c8449ca955be372844d5808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'ground_truths', 'answer', 'contexts'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")\n",
    "ds = fiqa_eval['baseline']\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use your own Parquet dataset. Required columns are:\n",
    "- `question`: `str` — original question\n",
    "- `ground_truths`: `List[str]` — ground truth answer(s) (accepts a list in case you'd like to provide multiple answer variations)\n",
    "- `answer`: `str` — generated answer\n",
    "- `contexts`: `List[str]` — retrieved document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "\n",
    "# ds = Dataset.from_parquet('/path/to/data/rag_results.parquet')\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to deposit a cheque issued to an associate...</td>\n",
       "      <td>[Have the check reissued to the proper payee.J...</td>\n",
       "      <td>\\nThe best way to deposit a cheque issued to a...</td>\n",
       "      <td>[Just have the associate sign the back and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I send a money order from USPS as a business?</td>\n",
       "      <td>[Sure you can.  You can fill in whatever you w...</td>\n",
       "      <td>\\nYes, you can send a money order from USPS as...</td>\n",
       "      <td>[Sure you can.  You can fill in whatever you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 EIN doing business under multiple business n...</td>\n",
       "      <td>[You're confusing a lot of things here. Compan...</td>\n",
       "      <td>\\nYes, it is possible to have one EIN doing bu...</td>\n",
       "      <td>[You're confusing a lot of things here. Compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applying for and receiving business credit</td>\n",
       "      <td>[\"I'm afraid the great myth of limited liabili...</td>\n",
       "      <td>\\nApplying for and receiving business credit c...</td>\n",
       "      <td>[Set up a meeting with the bank that handles y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401k Transfer After Business Closure</td>\n",
       "      <td>[You should probably consult an attorney. Howe...</td>\n",
       "      <td>\\nIf your employer has closed and you need to ...</td>\n",
       "      <td>[The time horizon for your 401K/IRA is essenti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to deposit a cheque issued to an associate...   \n",
       "1  Can I send a money order from USPS as a business?   \n",
       "2  1 EIN doing business under multiple business n...   \n",
       "3         Applying for and receiving business credit   \n",
       "4               401k Transfer After Business Closure   \n",
       "\n",
       "                                       ground_truths  \\\n",
       "0  [Have the check reissued to the proper payee.J...   \n",
       "1  [Sure you can.  You can fill in whatever you w...   \n",
       "2  [You're confusing a lot of things here. Compan...   \n",
       "3  [\"I'm afraid the great myth of limited liabili...   \n",
       "4  [You should probably consult an attorney. Howe...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\nThe best way to deposit a cheque issued to a...   \n",
       "1  \\nYes, you can send a money order from USPS as...   \n",
       "2  \\nYes, it is possible to have one EIN doing bu...   \n",
       "3  \\nApplying for and receiving business credit c...   \n",
       "4  \\nIf your employer has closed and you need to ...   \n",
       "\n",
       "                                            contexts  \n",
       "0  [Just have the associate sign the back and the...  \n",
       "1  [Sure you can.  You can fill in whatever you w...  \n",
       "2  [You're confusing a lot of things here. Compan...  \n",
       "3  [Set up a meeting with the bank that handles y...  \n",
       "4  [The time horizon for your 401K/IRA is essenti...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "df = ds.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8a69c",
   "metadata": {},
   "source": [
    "Lets import metrics that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17bcf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from ragas.metrics.critique import (\n",
    "    AspectCritique,\n",
    "    coherence,\n",
    "    conciseness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1201199",
   "metadata": {},
   "source": [
    "Now lets swap out the default `ChatOpenAI` with `BedrockChat`. Init a new instance of `BedrockChat` with the `model_id` of the model you want to use. You will also have to change the `BedrockEmbeddings` in the metrics that use them, which in our case is `answer_relevance`.\n",
    "\n",
    "In order to use the new `BedrockChat` llm instance with Ragas metrics, you have to create a new instance of `RagasLLM` using the `ragas.llms.LangchainLLM` wrapper. Its a simple wrapper around langchain that make Langchain LLM/Chat instances compatible with how Ragas metrics will use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40406a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from ragas.llms import LangchainLLM\n",
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "config = {\n",
    "    # NOTE: This has only been tested with Claude models!\n",
    "    \"model_id\": \"anthropic.claude-instant-v1\", # E.g \"anthropic.claude-v2\"\n",
    "    # NOTE: No need to set Temperature: it is set by the individual metrics (to 0.0 or 0.2 depending on the metric)\n",
    "    \"model_kwargs\": {\n",
    "        \"max_tokens_to_sample\": 1000,\n",
    "    },\n",
    "    \"embedding_model_id\": \"amazon.titan-embed-text-v1\",\n",
    "}\n",
    "\n",
    "boto_config = Config(\n",
    "    retries={\n",
    "        \"max_attempts\": 20,\n",
    "        \"mode\": \"adaptive\"\n",
    "    },\n",
    ")\n",
    "\n",
    "bedrock_inference = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    config=boto_config,\n",
    ")\n",
    "\n",
    "# Initialize BedrockChat\n",
    "bedrock_model = BedrockChat(\n",
    "    client=bedrock_inference,\n",
    "    model_id=config[\"model_id\"],\n",
    "    model_kwargs=config[\"model_kwargs\"],\n",
    ")\n",
    "\n",
    "# wrapper around BedrockChat\n",
    "ragas_bedrock_model = LangchainLLM(bedrock_model)\n",
    "\n",
    "# Initialize BedrockEmbeddings\n",
    "bedrock_embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_inference,\n",
    "    model_id=config[\"embedding_model_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will swap in custom prompts for each metric that have been tuned perform better with Anthropic Claude models. We can also change other metrics' settings here. For metrics that support it, the `strictness` parameter will run a metric evaluation multiple times and select a mean or majority answer (depending on the metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.prompts.langchain import anthropic_prompts\n",
    "\n",
    "context_recall.human_template = anthropic_prompts.CONTEXT_RECALL_HUMAN\n",
    "context_recall.ai_template = anthropic_prompts.CONTEXT_RECALL_AI\n",
    "\n",
    "context_precision.human_template = anthropic_prompts.CONTEXT_PRECISION_HUMAN\n",
    "context_precision.ai_template = anthropic_prompts.CONTEXT_PRECISION_AI\n",
    "\n",
    "answer_relevancy.human_template = anthropic_prompts.ANSWER_RELEVANCY_HUMAN\n",
    "answer_relevancy.ai_template = anthropic_prompts.ANSWER_RELEVANCY_AI\n",
    "\n",
    "faithfulness.statements_human_template = anthropic_prompts.FAITHFULNESS_STATEMENTS_HUMAN\n",
    "faithfulness.statements_ai_template = anthropic_prompts.FAITHFULNESS_STATEMENTS_AI\n",
    "faithfulness.verdict_human_template = anthropic_prompts.FAITHFULNESS_VERDICTS_HUMAN\n",
    "faithfulness.verdict_ai_template = anthropic_prompts.FAITHFULNESS_VERDICTS_AI\n",
    "\n",
    "answer_similarity.threshold = None\n",
    "\n",
    "answer_correctness.answer_similarity = answer_similarity\n",
    "answer_correctness.faithfulness = faithfulness\n",
    "\n",
    "coherence.human_template = anthropic_prompts.ASPECT_CRITIQUE_HUMAN\n",
    "coherence.ai_template = anthropic_prompts.ASPECT_CRITIQUE_AI\n",
    "coherence.definition = (\n",
    "    \"Does the submission present ideas, information, or arguments in a \"\n",
    "    \"logically sequential manner, clearly distinguishing main points from \"\n",
    "    \"supporting details? Evaluate the structure rigorously, ensuring each \"\n",
    "    \"part contributes directly to the overall message or argument. \"\n",
    "    \"Disregard submissions with any tangential or poorly connected content. \"\n",
    "    \"Be very strict!\"\n",
    ")\n",
    "coherence.strictness = 3\n",
    "\n",
    "conciseness.human_template = anthropic_prompts.ASPECT_CRITIQUE_HUMAN\n",
    "conciseness.ai_template = anthropic_prompts.ASPECT_CRITIQUE_AI\n",
    "conciseness.definition = (\n",
    "    \"Evaluate if the submission communicates its ideas or information using \"\n",
    "    \"the fewest possible words, without loss of clarity. Reject submissions with \"\n",
    "    \"any redundant, repetitive, cut-off, or extraneous details, regardless of their \"\n",
    "    \"relevance to the main topic. The focus should be on brevity and directness. \"\n",
    "    \"Be very strict!\"\n",
    ")\n",
    "\n",
    "conciseness.strictness = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define custom metrics with the `AspectCritique` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "awareness = AspectCritique(\n",
    "    name=\"awareness\",\n",
    "    definition=(\n",
    "        \"Assess the submission's ability to correctly judge context sufficiency. Answer 'Yes' if the context \"\n",
    "        \"is insufficient and the model identifies it as such, or if the context is sufficient and the model \"\n",
    "        \"answers the question. Answer 'No' if the context is insufficient but the model fails to recognize \"\n",
    "        \"this, or if the context is sufficient but the model incorrectly deems it insufficient. The focus \"\n",
    "        \"should be on the model's accuracy in evaluating the sufficiency of the context for the given question.\"\n",
    "    )\n",
    ")\n",
    "awareness.human_template = anthropic_prompts.ASPECT_GT_CRITIQUE_HUMAN\n",
    "awareness.ai_template = anthropic_prompts.ASPECT_CRITIQUE_AI\n",
    "awareness.strictness = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll list all of metrics we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Comment out any metrics you don't want to use\n",
    "metrics = [\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    "    coherence,\n",
    "    conciseness,\n",
    "    awareness,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll change the LLM and embedding models used for each metric. Here we will separately list all metrics, since in some cases we'll want to apply the changes even to metrics that are not listed above. This is because some metrics have dependencies on others (e.g. `answer_correctness`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all metrics\n",
    "all_metrics = [\n",
    "    context_recall, context_precision, answer_relevancy,\n",
    "    faithfulness, answer_similarity, answer_correctness,\n",
    "    coherence, conciseness, awareness\n",
    "]\n",
    "\n",
    "# Set attributes on metrics\n",
    "for m in all_metrics:\n",
    "    m.__setattr__(\"llm\", ragas_bedrock_model)\n",
    "    m.__setattr__(\"embeddings\", bedrock_embeddings)\n",
    "    m.__setattr__(\"batch_size\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ecd5a",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Running the evalutation is as simple as calling evaluate on the `Dataset` with the metrics of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\".*promote has been superseded by mode='default'.*\")\n",
    "\n",
    "# NOTE: Only used when running in a Jupyter notebook, otherwise comment or remove this function.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:46<00:00, 23.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:33<00:00, 16.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [coherence]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [conciseness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:22<00:00, 11.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [awareness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 192 ms, total: 2.59 s\n",
      "Wall time: 3min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.6840, 'context_precision': 0.8000, 'answer_relevancy': 0.8484, 'faithfulness': 0.9178, 'answer_similarity': 0.6880, 'answer_correctness': 0.6826, 'coherence': 1.0000, 'conciseness': 0.2667, 'awareness': 0.7000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(ds, metrics=metrics)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.6839682539682539,\n",
       " 'context_precision': 0.8,\n",
       " 'answer_relevancy': 0.8484158299742813,\n",
       " 'faithfulness': 0.9177777777777778,\n",
       " 'answer_similarity': 0.6879575691920328,\n",
       " 'answer_correctness': 0.6825502131674449,\n",
       " 'coherence': 1.0,\n",
       " 'conciseness': 0.26666666666666666,\n",
       " 'awareness': 0.7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average results\n",
    "average_results = result.copy()\n",
    "average_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dc0ec2",
   "metadata": {},
   "source": [
    "And there you have the it, all the scores you need. now if we want to dig into the results and figure out examples where your pipeline performed worse or really good you can easily convert it into a pandas array and use your standard analytics tools too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8686bf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "      <th>awareness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to deposit a cheque issued to an associate...</td>\n",
       "      <td>[Just have the associate sign the back and the...</td>\n",
       "      <td>\\nThe best way to deposit a cheque issued to a...</td>\n",
       "      <td>[Have the check reissued to the proper payee.J...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941635</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740307</td>\n",
       "      <td>0.536820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I send a money order from USPS as a business?</td>\n",
       "      <td>[Sure you can.  You can fill in whatever you w...</td>\n",
       "      <td>\\nYes, you can send a money order from USPS as...</td>\n",
       "      <td>[Sure you can.  You can fill in whatever you w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871439</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 EIN doing business under multiple business n...</td>\n",
       "      <td>[You're confusing a lot of things here. Compan...</td>\n",
       "      <td>\\nYes, it is possible to have one EIN doing bu...</td>\n",
       "      <td>[You're confusing a lot of things here. Compan...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.917308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610433</td>\n",
       "      <td>0.638550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applying for and receiving business credit</td>\n",
       "      <td>[Set up a meeting with the bank that handles y...</td>\n",
       "      <td>\\nApplying for and receiving business credit c...</td>\n",
       "      <td>[\"I'm afraid the great myth of limited liabili...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.662891</td>\n",
       "      <td>0.831446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401k Transfer After Business Closure</td>\n",
       "      <td>[The time horizon for your 401K/IRA is essenti...</td>\n",
       "      <td>\\nIf your employer has closed and you need to ...</td>\n",
       "      <td>[You should probably consult an attorney. Howe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259844</td>\n",
       "      <td>0.254922</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to deposit a cheque issued to an associate...   \n",
       "1  Can I send a money order from USPS as a business?   \n",
       "2  1 EIN doing business under multiple business n...   \n",
       "3         Applying for and receiving business credit   \n",
       "4               401k Transfer After Business Closure   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Just have the associate sign the back and the...   \n",
       "1  [Sure you can.  You can fill in whatever you w...   \n",
       "2  [You're confusing a lot of things here. Compan...   \n",
       "3  [Set up a meeting with the bank that handles y...   \n",
       "4  [The time horizon for your 401K/IRA is essenti...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\nThe best way to deposit a cheque issued to a...   \n",
       "1  \\nYes, you can send a money order from USPS as...   \n",
       "2  \\nYes, it is possible to have one EIN doing bu...   \n",
       "3  \\nApplying for and receiving business credit c...   \n",
       "4  \\nIf your employer has closed and you need to ...   \n",
       "\n",
       "                                       ground_truths  context_recall  \\\n",
       "0  [Have the check reissued to the proper payee.J...             0.5   \n",
       "1  [Sure you can.  You can fill in whatever you w...             1.0   \n",
       "2  [You're confusing a lot of things here. Compan...             0.8   \n",
       "3  [\"I'm afraid the great myth of limited liabili...             1.0   \n",
       "4  [You should probably consult an attorney. Howe...             0.0   \n",
       "\n",
       "   context_precision  answer_relevancy  faithfulness  answer_similarity  \\\n",
       "0                1.0          0.941635      0.666667           0.740307   \n",
       "1                1.0          0.962120      1.000000           0.871439   \n",
       "2                1.0          0.917308      1.000000           0.610433   \n",
       "3                1.0          0.667156      1.000000           0.662891   \n",
       "4                1.0          0.814123      1.000000           0.259844   \n",
       "\n",
       "   answer_correctness  coherence  conciseness  awareness  \n",
       "0            0.536820          1            1          1  \n",
       "1            0.935719          1            0          1  \n",
       "2            0.638550          1            0          0  \n",
       "3            0.831446          1            1          1  \n",
       "4            0.254922          1            0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs\n",
    "\n",
    "You can access the logs for each metric from metric objects themselves. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompts', 'responses', 'sentences', 'scores'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_recall.logs.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
