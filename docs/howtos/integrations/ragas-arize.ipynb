{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c367aa-e0a3-4116-bda7-7b81404211fd",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Introduction]()\n",
    "- [Testset generation]()\n",
    "- [Build RAG with llama-index]()\n",
    "- [Tracing using Phoenix]()\n",
    "- [Evaluation]()\n",
    "- [Embedding analysis]()\n",
    "- [Conclusion]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf25a1-02bc-43c7-82e9-93e362485b74",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4899e7a-43ef-4ae7-8f12-0024037a0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f707d3-e921-4f81-bbfb-a2ddb917c79d",
   "metadata": {},
   "source": [
    "## Synthetic Test data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548a0aba-a055-4262-8bd2-ee9e11cfd3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "Cloning into 'prompt-engineering-papers'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
      "remote: Total 69 (delta 0), reused 0 (delta 0), pack-reused 4\u001b[K\n",
      "Unpacking objects: 100% (69/69), 14.95 MiB | 10.15 MiB/s, done.\n",
      "Filtering content: 100% (31/31), 111.86 MiB | 21.30 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git lfs install\n",
    "! git clone https://huggingface.co/datasets/explodinggradients/prompt-engineering-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787ddbfa-cb14-4529-bb51-9873f75a3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea5e2125-3d3a-4a09-b307-24ab443087d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./prompt-engineering-papers\"\n",
    "reader = SimpleDirectoryReader(dir_path,num_files_limit=2)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d7e1d0-4c6e-4fd8-bfb8-be7b42d3de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c29b36d3a740dca6c2297b565ac346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "# generator with openai models\n",
    "generator = TestsetGenerator.with_openai()\n",
    "\n",
    "# set question type distribution\n",
    "distribution = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "\n",
    "# generate testset\n",
    "testset = generator.generate_with_llamaindex_docs(documents, test_size=10, distributions=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ca9d1a-9ae9-4b0b-9ba7-2bfe56088097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the lattice width of a normal set rel...</td>\n",
       "      <td>[1miisapathofminimallength, then ‚à•u‚Ä≤‚àív‚Ä≤‚à• ‚â§r¬∑‚à•M...</td>\n",
       "      <td>The relationship between the lattice width of ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some strategies proposed to enhance t...</td>\n",
       "      <td>[ parameter adap-\\ntation to learn the best mo...</td>\n",
       "      <td>Some strategies proposed to enhance the in-con...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the information-theoretic perspective...</td>\n",
       "      <td>[ Trans-\\nformers can implement a proper funct...</td>\n",
       "      <td>The information-theoretic perspective explains...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the use of ICL in data engineering ap...</td>\n",
       "      <td>[ 2023; He et al., 2023) and\\ntext-to-SQL (Pou...</td>\n",
       "      <td>The answer is not present in the context.</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the proof utilize the concept of a Ma...</td>\n",
       "      <td>[16 CAPRICE STANLEY AND TOBIAS WINDISCH\\nProof...</td>\n",
       "      <td>The answer to the question is not present in t...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the lattice width of a normal set rel...   \n",
       "1  What are some strategies proposed to enhance t...   \n",
       "2  How does the information-theoretic perspective...   \n",
       "3  How does the use of ICL in data engineering ap...   \n",
       "4  How does the proof utilize the concept of a Ma...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [1miisapathofminimallength, then ‚à•u‚Ä≤‚àív‚Ä≤‚à• ‚â§r¬∑‚à•M...   \n",
       "1  [ parameter adap-\\ntation to learn the best mo...   \n",
       "2  [ Trans-\\nformers can implement a proper funct...   \n",
       "3  [ 2023; He et al., 2023) and\\ntext-to-SQL (Pou...   \n",
       "4  [16 CAPRICE STANLEY AND TOBIAS WINDISCH\\nProof...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The relationship between the lattice width of ...         simple   \n",
       "1  Some strategies proposed to enhance the in-con...         simple   \n",
       "2  The information-theoretic perspective explains...         simple   \n",
       "3          The answer is not present in the context.         simple   \n",
       "4  The answer to the question is not present in t...         simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df.to_csv(\"ragas_testdata.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded50764-cd14-402b-93fd-0e8377b88ddd",
   "metadata": {},
   "source": [
    "## Build RAG with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f31213-78b2-47cc-8e60-5e7b3a94319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ef28bc-28b7-4ba7-94ea-949107ffb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "llama_index.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2597314-d6de-412d-b00c-3e00297746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "\n",
    "def build_query_engine(documents):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=ServiceContext.from_defaults(chunk_size=512),\n",
    "        embed_model=OpenAIEmbedding(),\n",
    "    )\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "    return query_engine\n",
    "\n",
    "\n",
    "def generate_response(query_engine, question):\n",
    "    \n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "            \"answer\":response.response,\n",
    "            \"contexts\":[c.node.get_content() for c in response.source_nodes]\n",
    "           }\n",
    "\n",
    "# Function to evaluate as Llama index does not support async evaluation for HFInference API\n",
    "def generate_ragas_dataset(query_engine, test_df):\n",
    "\n",
    "  test_questions = test_df[\"question\"].values\n",
    "  responses = [generate_response(query_engine,q) for q in test_questions]\n",
    "\n",
    "\n",
    "  dataset_dict = {\n",
    "        \"question\": test_questions,\n",
    "        \"answer\": [response[\"answer\"] for response in responses],\n",
    "        \"contexts\":[response[\"contexts\"] for response in responses],\n",
    "        \"ground_truth\":test_df[\"ground_truth\"].values.tolist()\n",
    "        \n",
    "  }\n",
    "  ds = Dataset.from_dict(dataset_dict)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66581bd9-ed40-4051-a7a7-9603eeb0e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Strategies proposed to enhance the in-context learning capability of language models include instruction tuning, generating instruction tuning datasets, connecting language models with powerful vision foundational models, and using proper data formatting and architecture designs. Additionally, in the speech area, treating text-to-speech synthesis as a language modeling task and using intermediate representations such as audio codec codes have been proposed to enhance in-context learning capability.',\n",
       " 'contexts': ['with instruction tuning, and the idea is also ex-\\nplored in the multi-modal scenarios as well. Re-\\ncent explorations first generate instruction tuning\\ndatasets transforming existing vision-language task\\ndataset (Xu et al., 2022; Li et al., 2023a) or with\\npower LLMs such as GPT-4 (Liu et al., 2023; Zhu\\net al., 2023a) , and connect LLMs with powerful vi-\\nsion foundational models such as BLIP-2 (Li et al.,\\n2023c) on these multi-modal datasets (Zhu et al.,\\n2023a; Dai et al., 2023).\\n9.3 Speech In-Context Learning\\nIn the speech area, Wang et al. (2023a) treated text-\\nto-speech synthesis as a language modeling task.\\nThey use audio codec codes as an intermediate rep-\\nresentation and propose the first TTS framework\\nwith strong in-context learning capability. Subse-\\nquently, V ALLE-X (Zhang et al., 2023b) extend the\\nidea to multi-lingual scenarios, demonstrating su-\\nperior performance in zero-shot cross-lingual text-\\nto-speech synthesis and zero-shot speech-to-speech\\ntranslation tasks.\\n3Takeaway :(1) Recent studies have explored\\nin-context learning beyond natural language with\\npromising results. Properly formatted data (e.g.,\\ninterleaved image-text datasets for vision-language\\ntasks) and architecture designs are key factors\\nfor activating the potential of in-context learning.\\nExploring it in a more complex structured space\\nsuch as for graph data is challenging and promis-\\ning (Huang et al., 2023a). (2) Findings in textual\\nin-context learning demonstration design and selec-\\ntion cannot be trivially transferred to other modal-\\nities. Domain-specific investigation is required to\\nfully leverage the potential of in-context learning\\nin various modalities.',\n",
       "  'Language models are few-shot learners. In Ad-\\nvances in Neural Information Processing Sys-\\ntems 33: Annual Conference on Neural Infor-\\nmation Processing Systems 2020, NeurIPS 2020,\\nDecember 6-12, 2020, virtual .\\nStephanie C. Y . Chan, Adam Santoro, Andrew K.\\nLampinen, Jane X. Wang, Aaditya Singh,\\nPierre H. Richemond, Jay McClelland, and Fe-\\nlix Hill. 2022. Data distributional properties\\ndrive emergent in-context learning in transform-\\ners.CoRR , abs/2205.05055.\\nMingda Chen, Jingfei Du, Ramakanth Pasunuru,\\nTodor Mihaylov, Srini Iyer, Veselin Stoyanov,\\nand Zornitsa Kozareva. 2022a. Improving in-\\ncontext few-shot learning via self-supervised\\ntraining. In Proceedings of the 2022 Conference\\nof the North American Chapter of the Associa-\\ntion for Computational Linguistics: Human Lan-\\nguage Technologies , pages 3558‚Äì3573, Seattle,\\nUnited States. Association for Computational\\nLinguistics.\\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKe-\\nown, and He He. 2022b. On the relation between\\nsensitivity and accuracy in in-context learning.\\nArXiv preprint , abs/2209.07661.\\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen R.\\nMcKeown, and He He. 2022c. On the relation\\nbetween sensitivity and accuracy in in-context\\nlearning. CoRR , abs/2209.07661.\\nYanda Chen, Ruiqi Zhong, Sheng Zha, George\\nKarypis, and He He. 2022d. Meta-learning via\\nlanguage model in-context tuning. In Proc. of\\nACL, pages 719‚Äì730, Dublin, Ireland. Associa-\\ntion for Computational Linguistics.']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(query_engine,test_df[\"question\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42e3b020-47f8-451a-907e-077486a3de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = build_query_engine(documents)\n",
    "ragas_eval_dataset = generate_responses(query_engine, test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a00c4a9f-9af6-4291-ac90-8395a9ac3bcb",
   "metadata": {},
   "source": [
    "![](../../_static/imgs/arize-tracing1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fc637b-fa0d-4e1d-8e7d-f37b8eb37d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186eaa7-ada2-4e13-94f2-5af903c26d79",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5bf278-b3ea-4e2a-9653-f724f41c067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24fae83-66e6-419d-a669-f491cef87935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import OpenInferenceTracer\n",
    "tracer = OpenInferenceTracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8fb386-259b-4110-8144-bf240898edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2495dea0b6af448fbccf5a39576e79ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_scores = evaluate(dataset=ragas_eval_dataset, \n",
    "                        metrics=[faithfulness, answer_correctness, context_recall, context_precision],\n",
    "                        callbacks=[tracer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51abdc4-20a3-45a4-b7a8-178d3881d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_correctness': 0.3806, 'context_recall': 0.5500}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394e287-4e3d-4833-a656-d208fa07055b",
   "metadata": {},
   "source": [
    "![](../../_static/imgs/arize-tracing2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b2520-b10f-42b1-bf18-6c3543bae7f9",
   "metadata": {},
   "source": [
    "## Embedding analysis\n",
    "TBD:\n",
    "- cluster queries\n",
    "- color each data point based on question type?\n",
    "- display average score for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc783c-9e45-43ed-b4cb-ea463e2c67bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
