{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c367aa-e0a3-4116-bda7-7b81404211fd",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Introduction]()\n",
    "- [Testset generation]()\n",
    "- [Build RAG with llama-index]()\n",
    "- [Tracing using Phoenix]()\n",
    "- [Evaluation]()\n",
    "- [Embedding analysis]()\n",
    "- [Conclusion]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf25a1-02bc-43c7-82e9-93e362485b74",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f707d3-e921-4f81-bbfb-a2ddb917c79d",
   "metadata": {},
   "source": [
    "## Synthetic Test data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548a0aba-a055-4262-8bd2-ee9e11cfd3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "Cloning into 'prompt-engineering-papers'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
      "remote: Total 69 (delta 0), reused 0 (delta 0), pack-reused 4\u001b[K\n",
      "Unpacking objects: 100% (69/69), 14.95 MiB | 10.15 MiB/s, done.\n",
      "Filtering content: 100% (31/31), 111.86 MiB | 21.30 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git lfs install\n",
    "! git clone https://huggingface.co/datasets/explodinggradients/prompt-engineering-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787ddbfa-cb14-4529-bb51-9873f75a3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea5e2125-3d3a-4a09-b307-24ab443087d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./prompt-engineering-papers\"\n",
    "reader = SimpleDirectoryReader(dir_path,num_files_limit=2)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d7e1d0-4c6e-4fd8-bfb8-be7b42d3de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c29b36d3a740dca6c2297b565ac346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "# generator with openai models\n",
    "generator = TestsetGenerator.with_openai()\n",
    "\n",
    "# set question type distribution\n",
    "distribution = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "\n",
    "# generate testset\n",
    "testset = generator.generate_with_llamaindex_docs(documents, test_size=10, distributions=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ca9d1a-9ae9-4b0b-9ba7-2bfe56088097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the lattice width of a normal set rel...</td>\n",
       "      <td>[1miisapathofminimallength, then ‚à•u‚Ä≤‚àív‚Ä≤‚à• ‚â§r¬∑‚à•M...</td>\n",
       "      <td>The relationship between the lattice width of ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some strategies proposed to enhance t...</td>\n",
       "      <td>[ parameter adap-\\ntation to learn the best mo...</td>\n",
       "      <td>Some strategies proposed to enhance the in-con...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the information-theoretic perspective...</td>\n",
       "      <td>[ Trans-\\nformers can implement a proper funct...</td>\n",
       "      <td>The information-theoretic perspective explains...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the use of ICL in data engineering ap...</td>\n",
       "      <td>[ 2023; He et al., 2023) and\\ntext-to-SQL (Pou...</td>\n",
       "      <td>The answer is not present in the context.</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the proof utilize the concept of a Ma...</td>\n",
       "      <td>[16 CAPRICE STANLEY AND TOBIAS WINDISCH\\nProof...</td>\n",
       "      <td>The answer to the question is not present in t...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the lattice width of a normal set rel...   \n",
       "1  What are some strategies proposed to enhance t...   \n",
       "2  How does the information-theoretic perspective...   \n",
       "3  How does the use of ICL in data engineering ap...   \n",
       "4  How does the proof utilize the concept of a Ma...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [1miisapathofminimallength, then ‚à•u‚Ä≤‚àív‚Ä≤‚à• ‚â§r¬∑‚à•M...   \n",
       "1  [ parameter adap-\\ntation to learn the best mo...   \n",
       "2  [ Trans-\\nformers can implement a proper funct...   \n",
       "3  [ 2023; He et al., 2023) and\\ntext-to-SQL (Pou...   \n",
       "4  [16 CAPRICE STANLEY AND TOBIAS WINDISCH\\nProof...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The relationship between the lattice width of ...         simple   \n",
       "1  Some strategies proposed to enhance the in-con...         simple   \n",
       "2  The information-theoretic perspective explains...         simple   \n",
       "3          The answer is not present in the context.         simple   \n",
       "4  The answer to the question is not present in t...         simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df.to_csv(\"ragas_testdata.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded50764-cd14-402b-93fd-0e8377b88ddd",
   "metadata": {},
   "source": [
    "## Build RAG with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f31213-78b2-47cc-8e60-5e7b3a94319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ef28bc-28b7-4ba7-94ea-949107ffb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "llama_index.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2597314-d6de-412d-b00c-3e00297746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "\n",
    "def build_query_engine(documents):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=ServiceContext.from_defaults(chunk_size=512),\n",
    "        embed_model=OpenAIEmbedding(),\n",
    "    )\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "    return query_engine\n",
    "\n",
    "# Function to evaluate as Llama index does not support async evaluation for HFInference API\n",
    "def generate_responses(query_engine, test_df):\n",
    "\n",
    "  test_questions, test_answers = test_df[\"question\"].values, test_df[\"ground_truth\"].values\n",
    "  responses = [query_engine.query(q) for q in test_questions]\n",
    "\n",
    "  answers = []\n",
    "  contexts = []\n",
    "  for r in responses:\n",
    "    answers.append(r.response)\n",
    "    contexts.append([c.node.get_content() for c in r.source_nodes])\n",
    "  dataset_dict = {\n",
    "        \"question\": test_questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "  }\n",
    "  if test_answers is not None:\n",
    "    dataset_dict[\"ground_truth\"] = test_answers\n",
    "  ds = Dataset.from_dict(dataset_dict)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e3b020-47f8-451a-907e-077486a3de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = build_query_engine(documents)\n",
    "ragas_eval_dataset = generate_responses(query_engine, test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a00c4a9f-9af6-4291-ac90-8395a9ac3bcb",
   "metadata": {},
   "source": [
    "![](../../_static/imgs/arize-tracing1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fc637b-fa0d-4e1d-8e7d-f37b8eb37d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186eaa7-ada2-4e13-94f2-5af903c26d79",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5bf278-b3ea-4e2a-9653-f724f41c067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24fae83-66e6-419d-a669-f491cef87935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import OpenInferenceTracer\n",
    "tracer = OpenInferenceTracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8fb386-259b-4110-8144-bf240898edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2495dea0b6af448fbccf5a39576e79ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_scores = evaluate(dataset=ragas_eval_dataset, \n",
    "                        metrics=[faithfulness, answer_correctness, context_recall, context_precision],\n",
    "                        callbacks=[tracer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51abdc4-20a3-45a4-b7a8-178d3881d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_correctness': 0.3806, 'context_recall': 0.5500}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394e287-4e3d-4833-a656-d208fa07055b",
   "metadata": {},
   "source": [
    "![](../../_static/imgs/arize-ragas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b2520-b10f-42b1-bf18-6c3543bae7f9",
   "metadata": {},
   "source": [
    "## Embedding analysis\n",
    "TBD:\n",
    "- cluster queries\n",
    "- color each data point based on question type?\n",
    "- display average score for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc783c-9e45-43ed-b4cb-ea463e2c67bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
