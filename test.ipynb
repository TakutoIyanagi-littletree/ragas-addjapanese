{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms.prompt import Prompt\n",
    "from ragas.metrics import (\n",
    "    context_recall, context_precision, answer_correctness, answer_relevancy,\n",
    "    AnswerCorrectness, AnswerRelevancy, ContextEntityRecall, Faithfulness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_recall.context_recall_prompt.dict()\n",
    "# context_precision.context_precision_prompt.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(context_recall.context_recall_prompt.format(\n",
    "#     question=\"Foo?\",\n",
    "#     context=\"The answer to the question Foo is Bar.\",\n",
    "#     answer=\"Bar\",\n",
    "# ).prompt_str)\n",
    "# print(context_precision.context_precision_prompt.format(\n",
    "#     question=\"Foo?\",\n",
    "#     context=\"The answer to the question Foo is Bar.\",\n",
    "#     answer=\"Bar\",\n",
    "# ).prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dummy_dataset_data = {\n",
    "    \"question\": [\n",
    "        \"Foo?\",\n",
    "        \"What day is today?\",\n",
    "        \"Who is the president of the United States?\",\n",
    "    ],\n",
    "    \"contexts\": [\n",
    "        [ \"The answer to the question Foo is Bar.\" ],\n",
    "        [ \"The answer to the question Foo is Bar.\" ],\n",
    "        [ \"The answer to the question Foo is Bar.\" ],\n",
    "    ],\n",
    "    \"ground_truth\": [\n",
    "        \"Bar on Thursday, otherwise Baz.\",\n",
    "        \"Thursday.\",\n",
    "        \"Joe Biden.\",\n",
    "    ],\n",
    "    \"answer\": [\n",
    "        \"Bar.\",\n",
    "        \"It is sunny today and it is Wednesday.\",\n",
    "        \"It is sunny today and it is Wednesday.\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(dummy_dataset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from ragas.llms.base import LangchainLLMWrapper\n",
    "\n",
    "import os, getpass\n",
    "%store -r OPENAI_API_KEY\n",
    "if not \"OPENAI_API_KEY\" in globals():\n",
    "    OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key:\")\n",
    "    %store OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "%store -r LANGCHAIN_API_KEY\n",
    "if not \"LANGCHAIN_API_KEY\" in globals():\n",
    "    LANGCHAIN_API_KEY = getpass.getpass(\"Enter your LangChain API key:\")\n",
    "    %store LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ragas-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "# answer_correctness = AnswerCorrectness(weights=[1.0, 0.0])\n",
    "# answer_relevancy = AnswerRelevancy(use_langchain_parser=False)\n",
    "context_entity_recall = ContextEntityRecall(use_langchain_parser=True)\n",
    "faithfulness = Faithfulness(use_langchain_parser=False)\n",
    "\n",
    "def eval_with_model(llm: BaseLanguageModel):\n",
    "    wrapper = LangchainLLMWrapper(llm)\n",
    "    result = evaluate(\n",
    "        dataset,\n",
    "        metrics=[\n",
    "            # context_recall,\n",
    "            # context_precision,\n",
    "            # answer_correctness,\n",
    "            # answer_relevancy,\n",
    "            # context_entity_recall,\n",
    "            faithfulness,\n",
    "        ],\n",
    "        llm=wrapper,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa23b8c6f4b42398aa13ba6bd2d17ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_entity_recall': 0.1111}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_with_model(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        temperature=1.0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b88c79f535446c595b61dd68a10b678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_entity_recall': 0.1667}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_with_model(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=1.0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da35b9de0e24fc9beb420ca1f9c0380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_entity_recall': 0.1111}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "eval_with_model(\n",
    "    Bedrock(\n",
    "        model_id=\"anthropic.claude-v2\",\n",
    "        streaming=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4dd7f034534f8398b75d5b9d9e89c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_entity_recall': 0.1111}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "eval_with_model(\n",
    "    Bedrock(\n",
    "        model_id=\"anthropic.claude-v2:1\",\n",
    "        streaming=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418cc4611c0648ba80b3d325e4c57427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_entity_recall': 0.1111}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_with_model(\n",
    "    BedrockChat(\n",
    "        model_id=\"anthropic.claude-instant-v1\",\n",
    "        streaming=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas.llms.prompt2 import get_prompt\n",
    "# from ragas.metrics._context_recall import ContextRecallClassificationAnswers\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "# from ragas.metrics import context_recall, context_precision\n",
    "\n",
    "# prompt = get_prompt(\n",
    "#     instructions=context_recall.context_recall_prompt.instruction,\n",
    "#     output_parser=JsonOutputParser(pydantic_object=ContextRecallClassificationAnswers),\n",
    "#     examples=context_recall.context_recall_prompt.examples,\n",
    "#     input_variables=context_recall.context_recall_prompt.input_keys,\n",
    "#     output_key=context_recall.context_recall_prompt.output_key,\n",
    "# )\n",
    "\n",
    "# print(prompt.format(question=\"Foo?\", answer=\"Bar!\", context=\"The answer to the question Foo? is Bar!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt.save(\"./test-prompt.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
