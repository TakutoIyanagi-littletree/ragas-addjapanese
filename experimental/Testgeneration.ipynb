{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88307ead",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34105067-eed8-4f09-913f-7043ff77cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader, SimpleDirectoryReader\n",
    "from ragas.testset import TestsetGenerator\n",
    "from llama_index import download_loader\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a154ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5cc66",
   "metadata": {},
   "source": [
    "## Assessing current state of test date generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc5970e-0873-4e06-9b68-3dda31b1d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ArxivReader = download_loader(\"ArxivReader\")\n",
    "\n",
    "loader = ArxivReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46684465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf.generic._base:could not convert string to float: '0.000000000000-2842171' : FloatObject (b'0.000000000000-2842171') invalid; use 0.0 instead\n"
     ]
    }
   ],
   "source": [
    "documents = loader.load_data(\"abs:LLM\",max_results=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df051faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dist =  {\n",
    "    \"simple\": 0.3,\n",
    "    \"reasoning\": 0.25,\n",
    "    \"multi_context\": 0.25,\n",
    "    \"conditional\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442cd5a6-6856-4488-8dae-be7195586986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                            | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the limitations of LOGIC -LM?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three categories of detectors for AI-generated text?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the legal knowledge memorization tasks in LawBench?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some concerns or issues caused by the inaccurate and biased outputs of large language models (LLMs)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                                | 1/50 [01:42<1:23:53, 102.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the details of the aggregation results for each tree search approach?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the differences between factuality issues and hallucination issues in language models?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███                                                 | 3/50 [02:18<31:11, 39.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the LLM translator in the ISR-LLM framework?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the correlations between the LLM exposure measures developed in this paper and previous measurements targeting software and AI?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the Personalized PageRank (PPR) score in content recommendation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n",
      " 12%|██████                                            | 6/50 [08:26<1:06:29, 90.67s/it]/Users/shahules/belar/src/ragas/testset/testset_generator.py:277: UserWarning: No neighbors exists\n",
      "  warnings.warn(\"No neighbors exists\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What tasks do LLMs excel in?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the estimated workload of the introductory programming course at Aalto University?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████▏                                        | 10/50 [08:47<29:43, 44.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What did the contracted annotators label for the remaining activities?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the categories of risks used to evaluate the behaviors of LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the primary observations regarding LLM compression methods based on the results shown in Figure 2?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question Q:What are some hot topics related to factuality issues in Large Language Models?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the four different training strategies examined for clinical concept extraction and relation extraction?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three categories of NLP tasks?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████▎                                   | 15/50 [09:51<16:57, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the components of the X2L interfaces in the X-LLM framework?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the compared responses from different types of prompting?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the baseline models adopted in this paper?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question How does prompt framing affect the accuracy of LLMs in predicting P17 facts?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the third training stage in X-LLM?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What percentage of help requests involved input and output issues?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What factors are considered when assessing exposure to language models in different occupations?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████▍                             | 21/50 [11:24<11:03, 22.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are some tuning-free approaches to cater LLMs to specific requirements?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different formats of prompts used to investigate the accuracy of language models under the influence of hallucination-inducing causes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████▌                      | 28/50 [12:04<05:39, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the error types observed in the analysis of LLMs on atomic knowledge?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the two metrics widely used to measure divergence in multi-inference uncertainty estimation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|████████████████████████████████████▋              | 36/50 [12:32<02:27, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the two novel attack methods proposed in this context?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the challenges in evaluating factuality in language models?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the benchmark datasets used for implicit hate speech detection?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the method used to extract article numbers from the model prediction?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the framework for automated measurement of responsible AI harms in generative AI applications?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the limitations of LLMs based on their training data?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question How does the performance of LLMs vary when the task requires additional temporal information compared to only structural information?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some common evaluation methods for Large Language Models (LLMs)?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the TRAN framework in LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of the two shortcuts, the distractor and the overlap anchor, on the model's performance in the ablation study?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the potential biases in LLMs and their impact on job predictions for women?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What types of attack strategies were used to compromise the performance of LLM detectors?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question How can LLMs evaluate the factuality of text generated by LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the summary statistics for the Suitability for Machine Learning measure?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the two categories of current editing methods?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the potential risks associated with the deployment of LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What were the main findings uncovered in the analysis of ShortcutQA in Table 2 regarding the distribution of distractor types?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the relationship between the age of crowd workers and their likelihood of using LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the findings from conducting extensive experiments with LLM4DyG regarding the spatial-temporal understanding abilities of LLMs on dynamic graphs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████▉     | 45/50 [16:07<01:19, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the two types of attack strategies used to compromise the performance of LLM detectors?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [16:27, 10.47s/it]                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the representative benchmarks for evaluating LLM hallucination and how do they differ in terms of evaluation format, task format, and metrics?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the benchmark datasets used to compare SSNA against five state-of-the-art baseline methods?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the advantages of using soft prompts with frozen LLMs in prompt-based learning?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [17:16,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three primary approaches for estimating the uncertainty of LLMs?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the benefits of incorporating Named Entity Recognition in the training process?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "78it [17:44,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question Is \"Black Mirror\" popular?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "91it [18:08,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the recommendation performances of different concatenation variants in the Movielens-1M dataset?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "105it [18:30,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the Factuality Issue in Large Language Models?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "120it [18:56,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the performance advantage of our TRAN framework over SALAM in the zero-shot setting?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some examples of biomedical and clinical language models mentioned in the table?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different categories of detectors considered in the study on the safety of large language models?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three groups of methods for evaluating truthfulness in language models?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "136it [20:06,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What tool is used to assess the reliability of generative chatbots?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "153it [20:23,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the error types observed in the analysis of LLMs on atomic knowledge?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the trainers offered by FATE-LLM for federated LLM learning scenarios?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "171it [21:10,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the limitations of LLM-based planners in terms of success rate?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of LLM-KICK in evaluating compressed LLMs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "190it [21:45,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the Dynamic Knowledge Fusion method in the context of LLM inference?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "210it [22:10,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of legal specific fine-tuning on the performance of LLMs in legal tasks?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "231it [22:37,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the encoding format used for classical planning problems?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "253it [23:03,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the impact of ChatGPT and GPT-4 on information retrieval tasks?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "276it [23:24,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the two types of distinct scenarios in which LLM-AUGMENTER is validated?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of explicitly asking for \"unsure\" as an answer in the evaluation methodology?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the impact of TEST on the classification accuracy of LLM?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the performance trend of the model SALAM on the BBH and BBQ datasets after different iterations of self-refinement?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "300it [24:11,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is one common approach to bridging the gap between natural language and various modalities?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "325it [24:41,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question Question: What are some methods used to evaluate hallucinations produced by language generation models (LLMs) according to existing benchmarks?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "351it [25:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What types of issues were more frequent in student programs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the hyperparameters adopted for small-scale datasets including C ORA, CITESEER, PUBMED, and W IKICS?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the performance rate of PaLM-SayCan in the simulated kitchen environment?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question Options:\n",
      "(A) The 78-year-old man\n",
      "(B) The 24-year-old friend\n",
      "(C) Both the 78-year-old man and the 24-year-old friend\n",
      "(D) Neither the 78-year-old man nor the 24-year-old friend\n",
      "\n",
      "Correct answer: (B) The 24-year-old friend.\n",
      "\n",
      "Previous answer: (A)\n",
      "\n",
      "Analysis: The model may have misinterpreted the context and the age difference between the two individuals. While both individuals are engaged in a conversation about how politics has changed, it is more likely that the younger friend, who has experienced fewer decades of political change, would be more open to embracing change.\n",
      "\n",
      "Guideline: When determining who embraces change in a conversation, consider the context and the individuals involved. Younger individuals are often more open to change, while older individuals may be more resistant or nostalgic for the past.\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question How can we incorporate KG information into LLM-based KGC?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the difference in scoring between HALOCHECK and selfcheckGPT-NLI in detecting contradictions among samples?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the effect of in-context interference on the accuracy of LLMs in a comparative study using factual entity probes and weakly associated entities?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "378it [26:34,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the differences between the guidelines provided by SALAM and SALAM w/ replay in Table 14?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the Marital Disputes Identification task?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the performance advantage of our TRAN framework over SALAM in the zero-shot setting?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the evaluation metrics used to measure the performance of LLMs in terms of atomic knowledge?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the dataset used for evaluating toxicity classification in English?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the average difference in results between English and other languages in math reasoning (MR) task?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What domains showed higher performance, but with low accuracy?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the accuracy comparison of GPT-4 for different size configurations of a rectangular grid?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "406it [28:26,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the three categories of integrating knowledge graphs (KGs) into large language models (LLMs) during pre-training?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "435it [28:41,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the study assistant in the given context?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the challenges in terms of efficiency for Federated LLM?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the maximum frequency in Figure 9 for the square, hexagonal, and triangular grid?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the formula for combining fDA-act (vi) scores?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the goal of KG-to-text generation and how does it connect knowledge graphs and texts?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "465it [29:33,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the proposed framework for enhancing LLM performance in long-horizon sequential task planning?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the average performance of SALAM on the three models M (Flan-T5, LLaMA, GPT-NeoX) according to the table?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of self-refinement on the executable rate and accuracy of the logical form in the FOLIO dataset?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "496it [30:23,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different error patterns observed when CodeGen fails to generate correct code?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some common issues that arise in LLMs, besides hallucination, and can you provide examples of each issue?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three different aggregation methods considered for aggregating search results in TS-LLM?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the Dynamic Knowledge Fusion method in the context of LLM inference?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "528it [31:22,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question Question: What is the impact of less naturally occurring questions on the factuality of LLMs in the Movie, Book, and Academics domains?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different types of security threats and defense methods in the integration of Federated Learning and Language Model (LLM)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "561it [32:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What datasets can be used to evaluate the question answering ability of LLMs?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the hobbies and interests that have honed my teamwork and leadership abilities?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the impact of compression on LLMs' capability for summarization?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the data sizes for the BBQ-Lite and TweetEval datasets?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "595it [33:11,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of temperature scaling in model calibration?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "630it [33:34,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the accuracy for math reasoning, commonsense reasoning, and knowledge access tasks in the TE dataset?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the limitations of ToG in the CWQ dataset analysis?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the impact of knowledge conflict on the performance of LLMs?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What datasets are used to evaluate ToG's ability on multi-hop knowledge-intensive reasoning tasks?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some common issues that LLMs may present besides hallucination?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of the DSTC7 Track 2 task?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "666it [34:48,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the effects and functions of Angong Niuhuang Pills?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "703it [35:04,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What LLM is used for the experiments in Section 5?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question A: First, the actor who portrayed the character Urethane Wheels Guy overdosed on drugs. The answer is not provided in the given context.\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the systematic approach proposed in the study to analyze the multilingual capabilities of LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of different policies on the utilization of the knowledge consolidator in the Customer Service scenario?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question Is there a relationship between productivity growth and exposure to LLM technologies?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the proposed system for improving large language models?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question How is the annotation difficulty of nodes in the dataset related to the clustering density of those nodes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "741it [36:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the initial state of the robot and the balls?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the proposed framework for enhancing LLM performance in long-horizon sequential task planning?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are some techniques used for integrating knowledge graphs into the training objective?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the application areas of LLMs in the included studies and what fields do they cover?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the MONITOR metric in assessing the factual knowledge of LLMs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the correlation between uncertainty scores and the performance of LLMs in NLP tasks, based on the results presented in Table 3?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the performance comparison between GatorTron-3.9B and GatorTron-8.9B models for cross-institution evaluation on the 2022 n2c2 SDoH dataset?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "780it [38:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the key steps in achieving TS FOR LLM?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the statistics of the evaluation datasets in Table 1?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of different feedback strategies on the performance of SALAM?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the correlation between human and GPT-4 annotations in terms of exposure at the occupation level?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of prompt translation in analyzing multilingual ability of LLMs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "820it [39:15,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different categories of tasks in which LLMs can be evaluated to demonstrate their performance?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the impact of the number of objects on the success rate of the ISR-LLM framework in different planning domains?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the experimental results for FedLLM using LoRA and P-Tuning-v2?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the distribution of head, torso, and tail entities in the given data sources (IMDb, Goodreads, MAG, DBLP, DBpedia)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "861it [40:05,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question Can LLMs be deceived by their own edits?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the purpose of the knowledge prefix adapter in the given table?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the three frameworks for unifying LLMs and KGs?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the method that integrates Chain-of-Thoughts into query retrieval?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "903it [40:54,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the purpose of LawBench and how many LLMs were examined?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the estimated prevalence of LLM use among crowd workers?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the two primary sources of knowledge acquisition for reducing hallucinations in LLMs' responses?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the contributions of X-LLM in terms of multimodal language modeling?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the different approaches to achieving representativeness in node selection?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the properties of various attack methods and their applicability to various detectors?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "946it [42:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the preference of expert human evaluators between human-written stories and GPT-2-generated stories based on the Likert scores obtained from LLM evaluation and human evaluation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "990it [42:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the different multi-hop reasoning datasets and their corresponding answer types?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1035it [43:11,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the proposed benchmark for evaluating LLMs' spatial-temporal understanding abilities on dynamic graphs?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the four distinct prompting strategies used in LLM-Rec to enhance personalized recommendation performance?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the overall performance of ChatGPT and LLaMA-33B in answering factual questions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1081it [43:52,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the performance of the CoT-greedy method in the Game24 task?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What subjects do LLMs struggle with in terms of computational proficiency?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question Q: What is an example of a reasoning error produced by large language models?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1128it [44:21,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': False}\n",
      "seed question Which player transferred to the 2013 Los Angeles Galaxy from a team with 12 international titles?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1176it [44:44,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the key findings regarding the performance of compressed LLMs in the ICRA-QA task when conditioned on external knowledge and used as in-context retrievers?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What is the impact of the rapid evolution of large language models on research replication and integration into teaching?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1225it [45:32,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True, 'is_table_present': True}\n",
      "seed question What are the two evaluation formats used to assess hallucination in LLMs, and how do they differ from each other?\n",
      "{'score': True, 'is_table_present': False}\n",
      "seed question What are the two new features of TS-LLM?\n",
      "{'score': True, 'is_table_present': True}\n",
      "seed question What is the definition of Large Language Models (LLMs)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1275it [46:14,  2.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_question</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some concerns or issues caused by the...</td>\n",
       "      <td>What are the concerns or issues caused by inac...</td>\n",
       "      <td>- \"Further, it is well known that commonly use...</td>\n",
       "      <td>The concerns or issues caused by inaccurate an...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the differences between factuality is...</td>\n",
       "      <td>What differentiates factuality issues from hal...</td>\n",
       "      <td>- Hallucinations primarily revolve around LLMs...</td>\n",
       "      <td>Factuality issues in language models refer to ...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the Personalized PageRa...</td>\n",
       "      <td>What is the purpose of the Personalized PageRa...</td>\n",
       "      <td>- \"In our study, we show an example of use Per...</td>\n",
       "      <td>The purpose of the Personalized PageRank (PPR)...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the estimated workload of the introduc...</td>\n",
       "      <td>What is the estimated workload of the introduc...</td>\n",
       "      <td>The estimated workload of this course is only ...</td>\n",
       "      <td>The estimated workload of the introductory pro...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the three categories of NLP tasks?</td>\n",
       "      <td>What are the three categories of NLP tasks?</td>\n",
       "      <td>- We classify NLP tasks into three distinct ca...</td>\n",
       "      <td>The three categories of NLP tasks are Reasonin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       seed_question  \\\n",
       "0  What are some concerns or issues caused by the...   \n",
       "1  What are the differences between factuality is...   \n",
       "2  What is the purpose of the Personalized PageRa...   \n",
       "3  What is the estimated workload of the introduc...   \n",
       "4        What are the three categories of NLP tasks?   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are the concerns or issues caused by inac...   \n",
       "1  What differentiates factuality issues from hal...   \n",
       "2  What is the purpose of the Personalized PageRa...   \n",
       "3  What is the estimated workload of the introduc...   \n",
       "4        What are the three categories of NLP tasks?   \n",
       "\n",
       "                                             context  \\\n",
       "0  - \"Further, it is well known that commonly use...   \n",
       "1  - Hallucinations primarily revolve around LLMs...   \n",
       "2  - \"In our study, we show an example of use Per...   \n",
       "3  The estimated workload of this course is only ...   \n",
       "4  - We classify NLP tasks into three distinct ca...   \n",
       "\n",
       "                                              answer question_type  \\\n",
       "0  The concerns or issues caused by inaccurate an...   conditional   \n",
       "1  Factuality issues in language models refer to ...   conditional   \n",
       "2  The purpose of the Personalized PageRank (PPR)...        simple   \n",
       "3  The estimated workload of the introductory pro...        simple   \n",
       "4  The three categories of NLP tasks are Reasonin...        simple   \n",
       "\n",
       "   episode_done  \n",
       "0         False  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetgenerator = TestsetGenerator.from_default(testset_distribution=test_dist,chunk_size=1024)\n",
    "test_size = 50\n",
    "testset = testsetgenerator.generate(documents, test_size=test_size)\n",
    "test_df = testset.to_pandas()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d58feb8-8604-4854-9d1d-7aa27495f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"arxiv_questions_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcb34d",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Conditional question evol is working\n",
    "- reasoning/multi context are not working as expected\n",
    "- Almost all questions are closed endeded \n",
    "- Almost all questions start with \"What\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86066a7a",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae07c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file.markdown_reader import MarkdownReader\n",
    "from llama_index.schema import Document\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d90da95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagasMdReader(MarkdownReader):\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_file_metadata(path):\n",
    "        \n",
    "        return {\"filename\":os.path.basename(path),\n",
    "                \"dirname\":os.path.dirname(path)}\n",
    "        \n",
    "    \n",
    "    def get_local_metadata(self, text):\n",
    "        \n",
    "        pattern = r\"\\[(.*?)\\]\\((?!https)(.*?)\\)\"\n",
    "        return re.findall(pattern, text)\n",
    "    \n",
    "    def load_data(\n",
    "        self, file: Path, extra_info: Optional[Dict] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Parse file into string.\"\"\"\n",
    "        tups = self.parse_tups(file)\n",
    "        results = []\n",
    "        \n",
    "        text = '\\n'.join([f\"\\n\\n{header}\\n{value}\" for header,value in tups])\n",
    "        local_metadata = self.get_local_metadata(text)\n",
    "\n",
    "        text = self.remove_hyperlinks(text)\n",
    "        extra_info = dict(extra_info,hyperlinks=local_metadata) if extra_info else {}\n",
    "        return [Document(text=text,metadata=extra_info)]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "06038931",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_reader = RagasMdReader(remove_hyperlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bca9d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm2(prompt, **kwargs):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=kwargs.get(\"model\", \"gpt-3.5-turbo\"),\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=kwargs.get(\"temperature\", 0),\n",
    "        top_p=kwargs.get(\"top_p\", 1),\n",
    "        frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n",
    "        presence_penalty=kwargs.get(\"presence_penalty\", 0.0),\n",
    "        max_tokens=kwargs.get(\"max_tokens\", 500),\n",
    "        n=kwargs.get(\"n\", 1),\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "feec19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.prompts import SEED_QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f614ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(\"/Users/shahules/Myprojects/rag-experiments/gitlab-handbook/data/handbook/communication/\", \n",
    "                               recursive=True,\n",
    "                              file_extractor={\".md\":md_reader},\n",
    "                            file_metadata=RagasMdReader.get_file_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dedcc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34704168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: _index.md\n",
      "dirname: /Users/shahules/Myprojects/rag-experiments/gitlab-handbook/data/handbook/communication\n",
      "hyperlinks: [('Positive Intent', '/handbook/values/#collaboration'), ('Values', '/handbook/values/'), ('market capitalization', '/handbook/being-a-public-company/#market-capitalization'), (\"all-remote setting](https://about.gitlab.com/company/culture/all-remote/terminology/), where team members are empowered to live and work where they're most fulfilled, mastering asynchronous workflows is vital to avoiding [dysfunction\", '/handbook/values/#five-dysfunctions'), ('manager of one', '/handbook/values/#managers-of-one'), ('Top misused terms page', '/handbook/communication/top-misused-terms/'), ('public by default', '/handbook/values/#public-by-default'), ('confidentiality levels', '/handbook/communication/confidentiality-levels/'), ('the internal Handbook](https://about.gitlab.com/handbook/handbook-usage/#the-internal-handbook) aligned with the guidelines | When you want to document information for team members that is [internal-only', '/handbook/communication/confidentiality-levels/#internal'), ('not public', '/handbook/communication/confidentiality-levels/#not-public'), ('limited access', '/handbook/communication/confidentiality-levels/#limited-access'), ('not public', '/handbook/communication/confidentiality-levels/#not-public'), ('internal-only', '/handbook/communication/confidentiality-levels/#internal'), ('not public', '/handbook/communication/confidentiality-levels/#not-public'), ('Slack', '/handbook/communication#slack'), ('guidelines on video chats', '#video-calls'), ('after 90 days', '/handbook/communication/#slack'), ('low-context communications](https://en.wikipedia.org/wiki/High-context_and_low-context_cultures) by being explicit in your communications. We are a remote-only company, located all over the world. Provide as much context as possible to avoid confusion. Relatedly, we use [ubiquitous language', '#ubiquitous-language'), ('been reported][issue-list]. If it has not been reported, and you are sure it is a bug, please [file an issue', '#issues'), ('Why handbook first?', '/handbook/handbook-usage/#why-handbook-first'), ('inclusion', '/handbook/values/#diversity-inclusion'), ('DIB', '/handbook/values/#diversity-inclusion'), ('`#thanks` slack channel', '/handbook/communication/#say-thanks'), (\"GitLab's values\", '/handbook/values/'), ('Values emoji', '/images/handbook/values-emoji.png'), ('Custom emoji', '/images/handbook/values-custom-emoji.png'), ('things that are not public by default', '/handbook/communication/confidentiality-levels/#not-public'), ('Minimal Viable Change (MVC)', '/handbook/values/#minimal-viable-change-mvc'), ('do not aim for consensus](https://about.gitlab.com/handbook/leadership/#making-decisions). Every MR is a [proposal', '/handbook/values/#make-a-proposal'), ('**smallest** viable and valuable thing', '/handbook/values/#iteration'), (\"that's how we ensure we create an environment of belonging for all team members](https://about.gitlab.com/company/culture/inclusion/#gitlabs-definition-of-diversity-inclusion--belonging). Merging your MR as-is without giving an answer or any response makes the commenters feel their opinions are unheard. If you are the [Directly Responsible Individual](https://about.gitlab.com/handbook/people-group/directly-responsible-individuals/) (DRI) who does not have to make a fast decision, you can choose not to change your MR, but you should acknowledge the comments or feedback, consider if they warrant a change to your MR, and [say why, not just what\", '/handbook/values/#say-why-not-just-what'), (\"we'll have to accept that people listened to us but don't owe us an explanation to have fast decisions based on everyone's input](https://about.gitlab.com/handbook/leadership/#making-decisions). The goals are to be transparent and collaborative--not to lose efficiency. Not everyone will agree, but we expect all people to [disagree, commit, and disagree\", '/handbook/values/#disagree-commit-and-disagree'), ('Manager Mention MR', '/handbook/communication/#scaling-merge-requests-through-manager-mention-mrs-formerly-consolidated-mrs'), ('non-public information', '/handbook/communication/confidentiality-levels/#not-public'), ('non-public information', '/handbook/communication/confidentiality-levels/#not-public'), ('Write down your questions', '/handbook/values/#write-things-down'), ('not-public information', '/handbook/communication/confidentiality-levels/#not-public'), ('Presenting', '/handbook/communication/#common-meeting-problems'), ('asynchronously', '/handbook/values/#bias-towards-asynchronous-communication'), ('Bias Towards Asynchronous Communication', '/handbook/values/#bias-towards-asynchronous-communication'), ('self-service and self-learning', '/handbook/values/#self-service-and-self-learning'), ('neurodiverse team members', '/handbook/values/#embracing-neurodiversity'), ('GitLab attendees', 'introductions.png'), ('PST morning block', '/handbook/communication/#emeaamer'), ('cross-regional collaboration', '/handbook/communication/#cross-regional-working-hours-recommendations'), ('PST afternoon block', '/handbook/communication/#apacamer'), ('cross-regional collaboration', '/handbook/communication/#cross-regional-working-hours-recommendations'), ('PST afternoon block', '/handbook/communication/#apacamer'), ('please place it on the GitLab Team Meetings Calendar', '/handbook/tools-and-tips/#gitlab-team-meetings-calendar'), ('Calendly', '/handbook/tools-and-tips/other-apps/#calendly'), (\"can't pay attention at the meeting\", '/handbook/communication/'), ('Zoom', '/handbook/tools-and-tips/zoom/'), ('Shush', '/handbook/tools-and-tips/other-apps/#shush'), ('Hybrid calls are annoying', '#hybrid-calls-are-annoying'), ('manterrupting', 'http://time.com/3666135/sheryl-sandberg-talking-while-female-manterruptions/'), ('do at Amazon](https://www.forbes.com/sites/carminegallo/2019/06/18/how-the-first-15-minutes-of-amazons-leadership-meetings-sparks-great-ideas-and-better-conversations/#6be165bd54ca). You can use the start of a meeting to review the materials for the meeting if you need to, given you do not have to be paying attention, but that should not delay the start of the meeting for the people that already have questions based on the materials. [Meetings start on time at GitLab.', '/handbook/communication/#scheduling-meetings'), ('cameras should always be on', '/handbook/communication/#video-calls'), ('manage their attention', '#you-are-the-manager-of-your-attention'), ('efficiency', '/handbook/values/#efficiency'), ('Meeting Cleanup Day', '/handbook/communication/#meeting-cleanup-day'), ('Meeting Cleanup Day', '/handbook/communication/#meeting-cleanup-day'), ('Ask Me Anything meetings', '/handbook/communication/ask-me-anything/'), ('Deep Dives page', '/handbook/communication/deep-dives/'), ('public by default', '/handbook/values/#public-by-default'), ('our templates', '/handbook/tools-and-tips/#updating-your-existing-slide-deck-theme'), ('Markdown', '/docs/markdown-guide/'), ('Markdown Style Guide', '/docs/markdown-guide/'), ('speak up', '/handbook/values/#share'), ('Single Source of Truth (SSoT)', '/handbook/values/#single-source-of-truth'), ('ISO dates](https://en.wikipedia.org/wiki/ISO_8601#Calendar_dates) in all writing and legal documents since other formats [lead to online confusion', 'http://xkcd.com/1179/'), ('secondary timezone in your Google calendar', '/handbook/tools-and-tips/#time-zone'), ('add multiple local times', '/handbook/tools-and-tips/#world-clock'), ('utilities', '/handbook/tools-and-tips/mac/#macos-utilities'), ('defined above', '#ubiquitous-language'), ('movie promotion to voters', ''), ('bias for action', '/handbook/values/#bias-for-action'), ('Religion and politics at work', '/handbook/values/#religion-and-politics-at-work'), ('proposals', '/handbook/values/#make-a-proposal'), ('iteration', '/handbook/values/#iteration'), ('merge request', '#start-with-a-merge-request'), ('unfurling', '/handbook/tools-and-tips/#unfurling-links-in-messages'), ('Direct messages discourage collaboration', 'http://blog.flowdock.com/2014/04/30/beware-of-private-conversations/'), ('our desire to avoid direct messages', '/handbook/communication/#avoid-direct-messages'), ('avoid direct messages', '/handbook/communication/#avoid-direct-messages'), ('use public channels', '/handbook/communication/#use-public-channels'), ('common channels and channel-naming conventions', '/handbook/communication/chat/'), (\"it's impossible to know everything\", '/handbook/values/#its-impossible-to-know-everything'), ('see others succeed', '/handbook/values/#see-others-succeed'), (\"it's impossible to know everything\", '/handbook/values/#its-impossible-to-know-everything'), ('many Slack channels', '/handbook/communication/chat/'), ('Chat handbook section', '/handbook/communication/chat/'), ('restricted permission levels', '#posting-in-company-fyi'), ('these topics', '/handbook/communication/#questions'), (\"important part of GitLab's culture\", '/handbook/communication/#say-thanks'), ('Diversity, Inclusion and Belonging Value', '/handbook/values/#diversity-inclusion'), ('more about inclusive language in our handbook', '/handbook/values/#inclusive-language--pronouns'), ('by having short toes', '/handbook/values/#short-toes'), ('read more about this in our handbook', '/handbook/communication/top-misused-terms/'), ('GitLab values', '/handbook/values/'), ('iterating', '/handbook/values/#iteration'), ('presentation', '#presentations'), (\"Pageless format](https://support.google.com/docs/answer/11528737?hl=en) is the preferred format for company documents that won't be printed. If you set your [default to Pageless](https://support.google.com/docs/answer/11528737?hl=en) then this will be applied to all future documents as well. If a document is likely going to be printed (for example, a contract) the older paged style is acceptable. See [Good practices and helpful tips\", '#good-practices--helpful-tips'), ('deprecate the Google Doc', '#how-to-deprecate-a-google-doc'), ('Google Doc Notifications', 'google-docs-notifications.png'), ('publish the document', '#how-to-publish-a-google-doc'), ('bookmark](https://support.google.com/docs/answer/45893?hl=en&co=GENIE.Platform%3DDesktop). If the notes are [limited access', '/handbook/communication/confidentiality-levels/#limited-access'), ('pageless format', '#pageless-is-the-gitlab-preferred-format'), ('handbook', '/handbook/'), ('Tools and Tips handbook', '/handbook/tools-and-tips/#zoom'), ('Family and friends first, work second', '/handbook/values/#family-and-friends-first-work-second'), ('everything you need to know about hosting or participating in a GitLab webinar', '/handbook/communication/zoom/webinars/'), ('Google Calendar - make calendar available setting', '/images/handbook/google-calendar-share.png'), ('these guidelines', '#meeting-introduction-guidelines'), ('Assume positive intent', '/handbook/values/#assume-positive-intent'), ('asynchronous](https://about.gitlab.com/company/culture/all-remote/asynchronous/) communication as the starting point and stays as open and transparent as we can by [communicating via text', '/handbook/communication/#writing-style-guidelines'), ('Single Source of Truth', '/handbook/documentation/#documentation-is-the-single-source-of-truth-ssot')]\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].get_metadata_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7da25175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([132.,  34.,  16.,   7.,   5.,   5.,   1.,   1.,   2.,   2.]),\n",
       " array([  12. ,  848.5, 1685. , 2521.5, 3358. , 4194.5, 5031. , 5867.5,\n",
       "        6704. , 7540.5, 8377. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPQUlEQVR4nO3df4xlZX3H8fenrIBg6y4y2eAu6a6R2FDTFjKhGBpjwCqCcfmDmDWmrkqzaWtbfzTRpf5B+ocJtMZfSavZgLo2FKErLURr7RYxpn+wOqhFYEFWfi5Z2LEKWk1U6rd/3Ae8rLM7O/fM7DDPvl/J5J7znHPu+Z4nZz5z7nPPvZOqQpLUl19b7gIkSYvPcJekDhnuktQhw12SOmS4S1KHVi13AQCnnnpqbdiwYbnLkKQV5fbbb/9eVU3Ntew5Ee4bNmxgZmZmucuQpBUlyUOHWuawjCR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdeg58QnVITZs+8Ky7fvBKy9etn1L0uF45S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjRvuCf5ZJIDSe4ca/u7JPckuSPJvyRZPbbs8iR7k9yb5LVLVLck6TCO5Mr908CFB7XtAl5eVb8DfAe4HCDJmcBm4LfbNv+Q5LhFq1aSdETmDfeq+irw/YPa/qOqnmqztwHr2/Qm4LNV9dOqegDYC5yziPVKko7AYoy5vx34YpteBzwytmxfa5MkHUWDwj3J+4GngGsn2HZrkpkkM7Ozs0PKkCQdZOJwT/JW4PXAm6uqWvOjwOljq61vbb+iqrZX1XRVTU9NTU1ahiRpDhOFe5ILgfcCb6iqn4wtuhnYnOSEJBuBM4CvDS9TkrQQq+ZbIcl1wKuAU5PsA65gdHfMCcCuJAC3VdWfVNVdSW4A7mY0XPOOqvq/pSpekjS3ecO9qt40R/M1h1n/A8AHhhQlSRrGT6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KF5wz3JJ5McSHLnWNspSXYlua89rmntSfKxJHuT3JHk7KUsXpI0tyO5cv80cOFBbduAW6rqDOCWNg/wOuCM9rMV+PjilClJWoh5w72qvgp8/6DmTcCONr0DuGSs/TM1chuwOslpi1SrJOkITTrmvraq9rfpx4C1bXod8MjYevta269IsjXJTJKZ2dnZCcuQJM1l8BuqVVVATbDd9qqarqrpqampoWVIksZMGu6PPz3c0h4PtPZHgdPH1lvf2iRJR9Gk4X4zsKVNbwFuGmt/S7tr5lzgybHhG0nSUbJqvhWSXAe8Cjg1yT7gCuBK4IYklwEPAW9sq/8bcBGwF/gJ8LYlqFmSNI95w72q3nSIRRfMsW4B7xhalCRpGD+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjQo3JO8O8ldSe5Mcl2SE5NsTLI7yd4k1yc5frGKlSQdmYnDPck64C+B6ap6OXAcsBm4CvhwVb0U+AFw2WIUKkk6ckOHZVYBz0+yCjgJ2A+cD+xsy3cAlwzchyRpgSYO96p6FPgg8DCjUH8SuB14oqqeaqvtA9bNtX2SrUlmkszMzs5OWoYkaQ5DhmXWAJuAjcCLgZOBC490+6raXlXTVTU9NTU1aRmSpDkMGZZ5NfBAVc1W1c+BG4HzgNVtmAZgPfDowBolSQs0JNwfBs5NclKSABcAdwO3Ape2dbYANw0rUZK0UEPG3HczeuP0G8C323NtB94HvCfJXuBFwDWLUKckaQFWzb/KoVXVFcAVBzXfD5wz5HklScP4CVVJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjQo3JOsTrIzyT1J9iR5RZJTkuxKcl97XLNYxUqSjszQK/ePAv9eVb8F/C6wB9gG3FJVZwC3tHlJ0lE0cbgneSHwSuAagKr6WVU9AWwCdrTVdgCXDCtRkrRQQ67cNwKzwKeSfDPJ1UlOBtZW1f62zmPA2rk2TrI1yUySmdnZ2QFlSJIONiTcVwFnAx+vqrOAH3PQEExVFVBzbVxV26tquqqmp6amBpQhSTrYkHDfB+yrqt1tfiejsH88yWkA7fHAsBIlSQs1cbhX1WPAI0le1pouAO4Gbga2tLYtwE2DKpQkLdiqgdv/BXBtkuOB+4G3MfqDcUOSy4CHgDcO3IckaYEGhXtVfQuYnmPRBUOeV5I0jJ9QlaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHRoc7kmOS/LNJJ9v8xuT7E6yN8n1SY4fXqYkaSEW48r9ncCesfmrgA9X1UuBHwCXLcI+JEkLMCjck6wHLgaubvMBzgd2tlV2AJcM2YckaeGGXrl/BHgv8Is2/yLgiap6qs3vA9bNtWGSrUlmkszMzs4OLEOSNG7icE/yeuBAVd0+yfZVtb2qpqtqempqatIyJElzWDVg2/OANyS5CDgR+A3go8DqJKva1ft64NHhZUqSFmLiK/equryq1lfVBmAz8OWqejNwK3BpW20LcNPgKiVJC7IU97m/D3hPkr2MxuCvWYJ9SJIOY8iwzDOq6ivAV9r0/cA5i/G8kqTJ+AlVSeqQ4S5JHTLcJalDizLmfqzasO0Ly7LfB6+8eFn2K2nl8MpdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHJg73JKcnuTXJ3UnuSvLO1n5Kkl1J7muPaxavXEnSkRhy5f4U8FdVdSZwLvCOJGcC24BbquoM4JY2L0k6iiYO96raX1XfaNM/AvYA64BNwI622g7gkoE1SpIWaFHG3JNsAM4CdgNrq2p/W/QYsPYQ22xNMpNkZnZ2djHKkCQ1g8M9yQuAzwHvqqofji+rqgJqru2qantVTVfV9NTU1NAyJEljBoV7kucxCvZrq+rG1vx4ktPa8tOAA8NKlCQt1JC7ZQJcA+ypqg+NLboZ2NKmtwA3TV6eJGkSqwZsex7wR8C3k3yrtf01cCVwQ5LLgIeANw6qUJK0YBOHe1X9F5BDLL5g0ueVJA3nJ1QlqUNDhmW0TDZs+8Ky7fvBKy9etn1LOnJeuUtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIb4XUgizXN1L6bZTSwnjlLkkdMtwlqUMOy2hFWM5/ULJcHIrSEF65S1KHDHdJ6pDhLkkdMtwlqUNL9oZqkguBjwLHAVdX1ZVLtS9JffCN88WzJOGe5Djg74E/BPYBX09yc1XdvRT7k3p0LAadFs9SDcucA+ytqvur6mfAZ4FNS7QvSdJBlmpYZh3wyNj8PuD3x1dIshXY2mb/N8m9E+7rVOB7E257rLCP5mcfHZ79M7+J+ihXDdrnbx5qwbJ9iKmqtgPbhz5Pkpmqml6EkrplH83PPjo8+2d+z7U+WqphmUeB08fm17c2SdJRsFTh/nXgjCQbkxwPbAZuXqJ9SZIOsiTDMlX1VJI/B77E6FbIT1bVXUuxLxZhaOcYYB/Nzz46PPtnfs+pPkpVLXcNkqRF5idUJalDhrskdWjFhnuSC5Pcm2Rvkm3LXc/RlOT0JLcmuTvJXUne2dpPSbIryX3tcU1rT5KPtb66I8nZY8+1pa1/X5Ity3VMSyHJcUm+meTzbX5jkt2tH65vb/aT5IQ2v7ct3zD2HJe39nuTvHaZDmVJJFmdZGeSe5LsSfIKz6FnS/Lu9jt2Z5Lrkpy4Ys6jqlpxP4zepP0u8BLgeOC/gTOXu66jePynAWe36V8HvgOcCfwtsK21bwOuatMXAV8EApwL7G7tpwD3t8c1bXrNch/fIvbTe4B/Aj7f5m8ANrfpTwB/2qb/DPhEm94MXN+mz2zn1gnAxnbOHbfcx7WI/bMD+OM2fTyw2nPoWf2zDngAeP7Y+fPWlXIerdQr92P66w2qan9VfaNN/wjYw+hE3MToF5b2eEmb3gR8pkZuA1YnOQ14LbCrqr5fVT8AdgEXHr0jWTpJ1gMXA1e3+QDnAzvbKgf3z9P9thO4oK2/CfhsVf20qh4A9jI691a8JC8EXglcA1BVP6uqJ/AcOtgq4PlJVgEnAftZIefRSg33ub7eYN0y1bKs2ku/s4DdwNqq2t8WPQasbdOH6q+e+/EjwHuBX7T5FwFPVNVTbX78WJ/ph7b8ybZ+z/2zEZgFPtWGrq5OcjKeQ8+oqkeBDwIPMwr1J4HbWSHn0UoNdwFJXgB8DnhXVf1wfFmNXg8ek/e5Jnk9cKCqbl/uWp7DVgFnAx+vqrOAHzMahnnGsXwOAbT3GzYx+kP4YuBkVtCrkpUa7sf81xskeR6jYL+2qm5szY+3l8q0xwOt/VD91Ws/nge8IcmDjIbszmf0vwVWt5fX8OxjfaYf2vIXAv9Dv/0Do6vHfVW1u83vZBT2nkO/9GrggaqaraqfAzcyOrdWxHm0UsP9mP56gzaOdw2wp6o+NLboZuDpuxW2ADeNtb+l3fFwLvBke+n9JeA1Sda0q5TXtLYVraour6r1VbWB0bnx5ap6M3ArcGlb7eD+ebrfLm3rV2vf3O6C2AicAXztKB3Gkqqqx4BHkrysNV0A3I3n0LiHgXOTnNR+557uo5VxHi33O9KT/jB69/47jN55fv9y13OUj/0PGL1cvgP4Vvu5iNH43i3AfcB/Aqe09cPon6d8F/g2MD32XG9n9AbPXuBty31sS9BXr+KXd8u8hNEv1V7gn4ETWvuJbX5vW/6Sse3f3/rtXuB1y308i9w3vwfMtPPoXxnd7eI59Ow++hvgHuBO4B8Z3fGyIs4jv35Akjq0UodlJEmHYbhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDv0/xJgE/u4fTFcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(doc.get_content()) for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef5db9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Webinars with the CEO\n",
      "\n",
      "When there's a webinar with the CEO, it is expected that the CEO Shadows execute the steps outlined in the `when the webinar is over` paragraph.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[-1].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca047cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1052549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SEED_QUESTION.prompt.template.format(context=documents[5].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "063951cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8Irq2CbbWAQhdw5XiN4d4oAMeZTEm at 0x7fac8fce6700> JSON: {\n",
       "  \"id\": \"chatcmpl-8Irq2CbbWAQhdw5XiN4d4oAMeZTEm\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1699507550,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"What are some myths about listening?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 486,\n",
       "    \"completion_tokens\": 7,\n",
       "    \"total_tokens\": 493\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd313ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
